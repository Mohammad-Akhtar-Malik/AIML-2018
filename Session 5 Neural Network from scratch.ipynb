{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "We will be implementing a 2 layer neural network in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#two layer neural network\n",
    "n_hidden=10\n",
    "n_input=10\n",
    "n_out=10\n",
    "#sample data\n",
    "n_sample=300\n",
    "#hyperparameters\n",
    "learning_rate=0.01\n",
    "momentum=0.9\n",
    "#non deterministic seeding\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#activation function\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-x))\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1-np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Our very own Neural Network\n",
    "Update Rules\n",
    "![](./images/backprop.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x,t,v,w,bv,bw):\n",
    "    #x=input data\n",
    "    #t=output\n",
    "    #v,w= weights of the two layers\n",
    "    #bv and bw bias\n",
    "    \n",
    "    #forward pass- matrix mul+bias followed by a non linearity\n",
    "    zj=np.dot(x,v)+bv\n",
    "    oj=np.tanh(zj)\n",
    "    \n",
    "    zk=np.dot(oj,w)+bw\n",
    "    ok=sigmoid(zk)\n",
    "    \n",
    "    #backprop\n",
    "    Ew=ok-t\n",
    "    Ev=tanh_prime(zj)*np.dot(w,Ew)\n",
    "    \n",
    "    #predict loss\n",
    "    #out[i, j] = a[i] * b[j]\n",
    "    dW=np.outer(oj,Ew)\n",
    "    dV=np.outer(x,Ev)\n",
    "    \n",
    "    #cross entropy loss\n",
    "    loss=-np.mean( t* np.log(ok)+(1-t)*np.log(1-ok))\n",
    "    \n",
    "    #returning loss and deltas \n",
    "    return loss,(dV,dW,Ev,Ew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x,v,w,bv,bw):\n",
    "    A=np.dot(x,v)+bv\n",
    "    z=np.tanh(A)\n",
    "    \n",
    "    B=np.dot(z,w)+bw\n",
    "    return (sigmoid(B)>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating layers\n",
    "v=np.random.normal(scale=0.1,size=(n_input,n_hidden))\n",
    "w=np.random.normal(scale=0.1,size=(n_hidden,n_out))\n",
    "\n",
    "bv=np.zeros(n_hidden)\n",
    "bw=np.zeros(n_out)\n",
    "\n",
    "#array of values\n",
    "params=[v,w,bv,bw]\n",
    "\n",
    "#generating data\n",
    "x=np.random.binomial(1,0.5,(n_sample,n_input))\n",
    "t=x^1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:0.45465070, Time: 0.0310 s\n",
      "Epoch: 1, Loss:0.13697961, Time: 0.0239 s\n",
      "Epoch: 2, Loss:0.06206941, Time: 0.0215 s\n",
      "Epoch: 3, Loss:0.04092746, Time: 0.0201 s\n",
      "Epoch: 4, Loss:0.03159958, Time: 0.0302 s\n",
      "Epoch: 5, Loss:0.02592744, Time: 0.0246 s\n",
      "Epoch: 6, Loss:0.02199575, Time: 0.0180 s\n",
      "Epoch: 7, Loss:0.01907812, Time: 0.0166 s\n",
      "Epoch: 8, Loss:0.01682099, Time: 0.0284 s\n",
      "Epoch: 9, Loss:0.01502363, Time: 0.0180 s\n",
      "Epoch: 10, Loss:0.01356039, Time: 0.0286 s\n",
      "Epoch: 11, Loss:0.01234775, Time: 0.0197 s\n",
      "Epoch: 12, Loss:0.01132776, Time: 0.0222 s\n",
      "Epoch: 13, Loss:0.01045887, Time: 0.0190 s\n",
      "Epoch: 14, Loss:0.00971052, Time: 0.0204 s\n",
      "Epoch: 15, Loss:0.00905971, Time: 0.0196 s\n",
      "Epoch: 16, Loss:0.00848887, Time: 0.0201 s\n",
      "Epoch: 17, Loss:0.00798436, Time: 0.0191 s\n",
      "Epoch: 18, Loss:0.00753542, Time: 0.0187 s\n",
      "Epoch: 19, Loss:0.00713347, Time: 0.0182 s\n",
      "Epoch: 20, Loss:0.00677160, Time: 0.0185 s\n",
      "Epoch: 21, Loss:0.00644415, Time: 0.0265 s\n",
      "Epoch: 22, Loss:0.00614650, Time: 0.0287 s\n",
      "Epoch: 23, Loss:0.00587477, Time: 0.0264 s\n",
      "Epoch: 24, Loss:0.00562576, Time: 0.0203 s\n",
      "Epoch: 25, Loss:0.00539674, Time: 0.0240 s\n",
      "Epoch: 26, Loss:0.00518541, Time: 0.0197 s\n",
      "Epoch: 27, Loss:0.00498981, Time: 0.0197 s\n",
      "Epoch: 28, Loss:0.00480824, Time: 0.0245 s\n",
      "Epoch: 29, Loss:0.00463926, Time: 0.0297 s\n",
      "Epoch: 30, Loss:0.00448161, Time: 0.0274 s\n",
      "Epoch: 31, Loss:0.00433419, Time: 0.0183 s\n",
      "Epoch: 32, Loss:0.00419603, Time: 0.0288 s\n",
      "Epoch: 33, Loss:0.00406629, Time: 0.0327 s\n",
      "Epoch: 34, Loss:0.00394423, Time: 0.0300 s\n",
      "Epoch: 35, Loss:0.00382919, Time: 0.0213 s\n",
      "Epoch: 36, Loss:0.00372058, Time: 0.0202 s\n",
      "Epoch: 37, Loss:0.00361787, Time: 0.0261 s\n",
      "Epoch: 38, Loss:0.00352061, Time: 0.0292 s\n",
      "Epoch: 39, Loss:0.00342836, Time: 0.0290 s\n",
      "Epoch: 40, Loss:0.00334076, Time: 0.0285 s\n",
      "Epoch: 41, Loss:0.00325746, Time: 0.0213 s\n",
      "Epoch: 42, Loss:0.00317815, Time: 0.0176 s\n",
      "Epoch: 43, Loss:0.00310255, Time: 0.0280 s\n",
      "Epoch: 44, Loss:0.00303042, Time: 0.0201 s\n",
      "Epoch: 45, Loss:0.00296151, Time: 0.0237 s\n",
      "Epoch: 46, Loss:0.00289562, Time: 0.0216 s\n",
      "Epoch: 47, Loss:0.00283255, Time: 0.0289 s\n",
      "Epoch: 48, Loss:0.00277213, Time: 0.0289 s\n",
      "Epoch: 49, Loss:0.00271419, Time: 0.0176 s\n",
      "Epoch: 50, Loss:0.00265858, Time: 0.0298 s\n",
      "Epoch: 51, Loss:0.00260517, Time: 0.0216 s\n",
      "Epoch: 52, Loss:0.00255383, Time: 0.0218 s\n",
      "Epoch: 53, Loss:0.00250444, Time: 0.0307 s\n",
      "Epoch: 54, Loss:0.00245689, Time: 0.0302 s\n",
      "Epoch: 55, Loss:0.00241108, Time: 0.0328 s\n",
      "Epoch: 56, Loss:0.00236692, Time: 0.0181 s\n",
      "Epoch: 57, Loss:0.00232432, Time: 0.0181 s\n",
      "Epoch: 58, Loss:0.00228320, Time: 0.0316 s\n",
      "Epoch: 59, Loss:0.00224348, Time: 0.0178 s\n",
      "Epoch: 60, Loss:0.00220510, Time: 0.0185 s\n",
      "Epoch: 61, Loss:0.00216798, Time: 0.0200 s\n",
      "Epoch: 62, Loss:0.00213207, Time: 0.0298 s\n",
      "Epoch: 63, Loss:0.00209730, Time: 0.0163 s\n",
      "Epoch: 64, Loss:0.00206363, Time: 0.0274 s\n",
      "Epoch: 65, Loss:0.00203101, Time: 0.0279 s\n",
      "Epoch: 66, Loss:0.00199938, Time: 0.0325 s\n",
      "Epoch: 67, Loss:0.00196870, Time: 0.0292 s\n",
      "Epoch: 68, Loss:0.00193892, Time: 0.0164 s\n",
      "Epoch: 69, Loss:0.00191002, Time: 0.0276 s\n",
      "Epoch: 70, Loss:0.00188195, Time: 0.0276 s\n",
      "Epoch: 71, Loss:0.00185467, Time: 0.0234 s\n",
      "Epoch: 72, Loss:0.00182816, Time: 0.0285 s\n",
      "Epoch: 73, Loss:0.00180238, Time: 0.0162 s\n",
      "Epoch: 74, Loss:0.00177730, Time: 0.0182 s\n",
      "Epoch: 75, Loss:0.00175290, Time: 0.0163 s\n",
      "Epoch: 76, Loss:0.00172914, Time: 0.0273 s\n",
      "Epoch: 77, Loss:0.00170600, Time: 0.0282 s\n",
      "Epoch: 78, Loss:0.00168346, Time: 0.0315 s\n",
      "Epoch: 79, Loss:0.00166149, Time: 0.0284 s\n",
      "Epoch: 80, Loss:0.00164008, Time: 0.0280 s\n",
      "Epoch: 81, Loss:0.00161920, Time: 0.0301 s\n",
      "Epoch: 82, Loss:0.00159883, Time: 0.0283 s\n",
      "Epoch: 83, Loss:0.00157896, Time: 0.0275 s\n",
      "Epoch: 84, Loss:0.00155957, Time: 0.0236 s\n",
      "Epoch: 85, Loss:0.00154063, Time: 0.0300 s\n",
      "Epoch: 86, Loss:0.00152214, Time: 0.0302 s\n",
      "Epoch: 87, Loss:0.00150407, Time: 0.0310 s\n",
      "Epoch: 88, Loss:0.00148642, Time: 0.0307 s\n",
      "Epoch: 89, Loss:0.00146917, Time: 0.0327 s\n",
      "Epoch: 90, Loss:0.00145230, Time: 0.0309 s\n",
      "Epoch: 91, Loss:0.00143581, Time: 0.0311 s\n",
      "Epoch: 92, Loss:0.00141968, Time: 0.0183 s\n",
      "Epoch: 93, Loss:0.00140390, Time: 0.0317 s\n",
      "Epoch: 94, Loss:0.00138846, Time: 0.0240 s\n",
      "Epoch: 95, Loss:0.00137334, Time: 0.0182 s\n",
      "Epoch: 96, Loss:0.00135854, Time: 0.0286 s\n",
      "Epoch: 97, Loss:0.00134405, Time: 0.0270 s\n",
      "Epoch: 98, Loss:0.00132986, Time: 0.0262 s\n",
      "Epoch: 99, Loss:0.00131596, Time: 0.0258 s\n"
     ]
    }
   ],
   "source": [
    "totalloss=[]\n",
    "for epoch in range(100):\n",
    "    err=[]\n",
    "    upd=[0]*len(params)\n",
    "    t0=time.clock()\n",
    "    #for each datapoint update weights\n",
    "    for i in range(x.shape[0]):\n",
    "        loss,grad=train(x[i],t[i],*params)\n",
    "        #update loss\n",
    "        for a in range(len(params)):\n",
    "            params[a]-=upd[a]\n",
    "        for b in range(len(params)):\n",
    "            upd[b]=learning_rate*grad[b]+momentum*upd[b]\n",
    "            \n",
    "        err.append(loss)\n",
    "        #print(loss)\n",
    "    totalloss.append(np.mean(err))    \n",
    "    print('Epoch: %d, Loss:%.8f, Time: %.4f s' %(\n",
    "        epoch,np.mean(err),time.clock()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd483d2b080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(totalloss)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data\n",
      "[1 0 1 1 1 1 0 1 0 0]\n",
      "Output should be\n",
      "[0 1 0 0 0 0 1 0 1 1]\n",
      "Output is\n",
      "[0 1 0 0 0 0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "x=np.random.binomial(1,0.5,n_input)\n",
    "print('Input data');\n",
    "print(x)\n",
    "print('Output should be')\n",
    "print(x^1)\n",
    "print('Output is')\n",
    "print(predict(x,*params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
